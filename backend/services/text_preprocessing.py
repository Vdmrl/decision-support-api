import re
from nltk.stem import WordNetLemmatizer


class Preprocessing:
    @staticmethod
    def lowercase(text: str) -> str:
        '''
        lower text
        '''
        return text.lower()

    @staticmethod
    def delete_not_letters(text: str) -> str:
        '''
        delete from text everything except lower cyrillic letters
        '''
        return " ".join(re.findall(r'[а-яё]+', text))

    @staticmethod
    def delete_stop_words(text: str) -> str:
        '''
        delete russian stopwords from text
        '''
        stopwords = {"и", "в", "во", "не", "что", "он", "на", "я", "с", "со", "как", "а", "то", "все", "она", "так",
                     "его", "но", "да", "ты", "к", "у", "же", "вы", "за", "бы", "по", "только", "ее", "мне", "было",
                     "вот", "от", "меня", "еще", "нет", "о", "из", "ему", "теперь", "когда", "даже", "ну", "вдруг",
                     "ли", "если", "уже", "или", "ни", "быть", "был", "него", "до", "вас", "нибудь", "опять", "уж",
                     "вам", "ведь", "там", "потом", "себя", "ничего", "ей", "может", "они", "тут", "где", "есть",
                     "надо", "ней", "для", "мы", "тебя", "их", "чем", "была", "сам", "чтоб", "без", "будто", "чего",
                     "раз", "тоже", "себе", "под", "будет", "ж", "тогда", "кто", "этот", "того", "потому", "этого",
                     "какой", "совсем", "ним", "здесь", "этом", "один", "почти", "мой", "тем", "чтобы", "нее", "сейчас",
                     "были", "куда", "зачем", "всех", "никогда", "можно", "при", "наконец", "два", "об", "другой",
                     "хоть", "после", "над", "больше", "тот", "через", "эти", "нас", "про", "всего", "них", "какая",
                     "много", "разве", "три", "эту", "моя", "впрочем", "хорошо", "свою", "этой", "перед", "иногда",
                     "лучше", "чуть", "том", "нельзя", "такой", "им", "более", "всегда", "конечно", "всю", "между"}
        return " ".join([word for word in text.split() if word not in stopwords])
